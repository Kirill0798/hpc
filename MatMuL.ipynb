{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MatMuL.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOJHSJlvb_Ra"
      },
      "source": [
        "!pip install pycuda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqvS_NrDtYKe"
      },
      "source": [
        "import numpy as np\n",
        "from timeit import default_timer as timer\n",
        "import pycuda.autoinit\n",
        "from pycuda.driver import In, Out, Context\n",
        "from pycuda.compiler import SourceModule\n",
        "\n",
        "BLOCK_SIZE = 32\n",
        "MATRIX_SIZES = [128, 256, 512, 1024, 2048]\n",
        "BLOCK = (BLOCK_SIZE, BLOCK_SIZE, 1)\n",
        "\n",
        "kernel = SourceModule(\n",
        "    \"\"\"\n",
        "    __global__ void matMul(float* a, float* b, float* c, int* N){\n",
        "        const int blockSize = %(BLOCK_SIZE)s;\n",
        "        int n = N[0];\n",
        "        int bx = blockIdx.x,\n",
        "            by = blockIdx.y,\n",
        "            tx = threadIdx.x,\n",
        "            ty = threadIdx.y;\n",
        "        int aStart = n * blockSize * by,\n",
        "            bStart = blockSize * bx;\n",
        "        int aStep = blockSize,\n",
        "            bStep = blockSize * n;\n",
        "        int blockCount = gridDim.x;\n",
        "        float sum = 0.0f;\n",
        "        int ia = aStart,\n",
        "            ib = bStart;\n",
        "\n",
        "        __shared__ float as[blockSize][blockSize];\n",
        "        __shared__ float bs[blockSize][blockSize];\n",
        "        for (int i = 0; i < blockCount; i++){\n",
        "          as[ty][tx] = a[ia + n * ty + tx];\n",
        "          bs[ty][tx] = b[ib + n * ty + tx];\n",
        "          __syncthreads ();\n",
        "          for ( int k = 0; k < blockSize; k++){\n",
        "            sum += as[ty][k] * bs[k][tx];\n",
        "          }\n",
        "          __syncthreads ();\n",
        "          ia += aStep;\n",
        "          ib += bStep;\n",
        "        }\n",
        "        c[n * blockSize * by + blockSize * bx + n * ty + tx] = sum;\n",
        "    }\n",
        "    \"\"\" % {\n",
        "        'BLOCK_SIZE' : BLOCK_SIZE\n",
        "    }\n",
        ")\n",
        "\n",
        "matMul = kernel.get_function(\"matMul\")\n",
        "\n",
        "\n",
        "def gpu(a, b, n):\n",
        "    N = np.array([n])\n",
        "    c  = np.zeros_like(a, dtype=np.float32)\n",
        "    grid_dim = (n // BLOCK_SIZE, n // BLOCK_SIZE)\n",
        "    matMul(In(a), In(b), Out(c), In(N), block=BLOCK, grid=grid_dim)\n",
        "    Context.synchronize()\n",
        "    return c\n",
        "\n",
        "\n",
        "def cpu(a, b):\n",
        "    return a.dot(b)\n",
        "\n",
        "\n",
        "def test(a, b, n):\n",
        "    start = timer()\n",
        "    cpu_res = cpu(a, b)\n",
        "    cpu_multiply_time = timer() - start\n",
        "\n",
        "    start = timer()\n",
        "    gpu_res = gpu(a, b, n)\n",
        "    gpu_multiply_time = timer() - start\n",
        "\n",
        "    return cpu_multiply_time * 1000, gpu_multiply_time * 1000, np.allclose(cpu_res, gpu_res)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4JH4LU9tYQU",
        "outputId": "d05ddf1f-6824-4943-fd33-18195f70ea08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "TEST_ROUND = 20\n",
        "\n",
        "print(\"Size | CPU time, ms | GPU time, ms | Speedup\")\n",
        "\n",
        "for size in MATRIX_SIZES:\n",
        "    cpu_time = 0\n",
        "    gpu_time = 0\n",
        "\n",
        "    for i in range(TEST_ROUND):\n",
        "        A = np.array(np.random.rand(size, size), dtype=np.float32)\n",
        "        B = np.array(np.random.rand(size, size), dtype=np.float32)\n",
        "        c_time, g_time, e = test(A, B, size)\n",
        "        cpu_time += c_time\n",
        "        gpu_time += g_time\n",
        "\n",
        "        if not e:\n",
        "            print(\"Size = {:d}, round = {:d}: results not equals\".format(size, i))\n",
        "\n",
        "    print(\"{:4d} | {:12.3f} | {:12.3f} | {:7.2f}\".format(size, cpu_time / TEST_ROUND, gpu_time / TEST_ROUND, cpu_time / gpu_time))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size | CPU time, ms | GPU time, ms | Speedup\n",
            " 128 |        0.293 |        0.661 |    0.44\n",
            " 256 |        0.638 |        0.899 |    0.71\n",
            " 512 |        4.608 |        2.926 |    1.57\n",
            "1024 |       35.526 |       11.086 |    3.20\n",
            "2048 |      266.146 |       59.547 |    4.47\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}